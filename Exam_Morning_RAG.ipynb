{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf56921",
   "metadata": {},
   "source": [
    "# Exam (morning): Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7fb22f",
   "metadata": {},
   "source": [
    "### Personal Details (please complete)\n",
    "Double Click on Cell to edit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d35a25",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td>First Name:</td>\n",
    "    <td>Kaspar</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Last Name:</td>\n",
    "    <td>Hänni</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Student ID:</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Modul:</td>\n",
    "    <td>Machine Learning 2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Exam Date / Raum / Zeit:</td>\n",
    "    <td>20.05.2025 / Raum: SM O2.01  / 10:15 – 11:30</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Erlaubte Hilfsmittel:</td>\n",
    "    <td>w.3ML2-WIN (Machine Leaning 2)<br>Open Book, Personal Computer, Internet Access</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>Not allowed:</td>\n",
    "  <td>The use of any form of generative AI (e.g., Copilot, ChatGPT) to assist in solving the exercise is not permitted. <br> However, using such tools as part of the exercise itself (e.g., making API calls to them if required by the task) is allowed. <br> Any form of communication or collaboration with other people is not permitted.</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61847f62",
   "metadata": {},
   "source": [
    "## Evaluation Criteria\n",
    "\n",
    "### <b style=\"color: gray;\">(maximum achievable points: 48)</b>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Category</th>\n",
    "      <th>Description</th>\n",
    "      <th>Points Distribution</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Code not executable or results not meaningful</td>\n",
    "      <td>The code contains errors that prevent it from running (e.g., syntax errors) or produces results that do not fit the question.</td>\n",
    "      <td>0 points</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Code executable, but with serious deficiencies</td>\n",
    "      <td>The code runs, but the results are incomplete due to major errors (e.g., fundamental errors when reading the data). Only minimal progress is evident.</td>\n",
    "      <td>25% of the maximum achievable points</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Code executable, but with moderate deficiencies</td>\n",
    "      <td>The code runs and delivers partially correct results, but there are significant errors (e.g., the data types of the imported data do not meet the requirements of the question). The results are comprehensible but incomplete or inaccurate.</td>\n",
    "      <td>50% of the maximum achievable points</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Code executable, but with minor deficiencies</td>\n",
    "      <td>The code runs and delivers a largely correct result, but minor errors (e.g., column name misspelled, timestamp not correctly formatted) affect the completeness of the result.</td>\n",
    "      <td>75% of the maximum achievable points</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Code executable and correct</td>\n",
    "      <td>The code runs flawlessly and delivers the correct result without deficiencies.</td>\n",
    "      <td>100% of the maximum achievable points</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8df3dd",
   "metadata": {},
   "source": [
    "## Python Libraries und Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9011e",
   "metadata": {},
   "source": [
    "## <b>Set Up (This part will <u>not</u> be evaluated!)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e253f40",
   "metadata": {},
   "source": [
    "#### <b>1.) Start a GitHub Codespaces instance based on your fork of this GitHub repository or open the notebook in Colab</b>\n",
    "#### <b>2.) Add API keys to either .env files for Codespaces or to the secrets for Colab</b>\n",
    "#### <b>3.) Please execute the two code cells below as soon as the Codespace/Colab has started and install the libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6e3474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/codespace/.python/current/lib/python3.12/site-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0.1\n",
      "    Uninstalling pip-25.0.1:\n",
      "      Successfully uninstalled pip-25.0.1\n",
      "Successfully installed pip-25.1.1\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.59 (from langchain-community)\n",
      "  Downloading langchain_core-0.3.60-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.25 (from langchain-community)\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain-community)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-community) (2.2.4)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.25->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain<1.0.0,>=0.3.25->langchain-community)\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.59->langchain-community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Downloading orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain-community)\n",
      "  Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.60-py3-none-any.whl (437 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "Downloading orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
      "Downloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.9/603.9 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, python-dotenv, pydantic-core, propcache, orjson, mypy-extensions, multidict, marshmallow, jsonpatch, httpx-sse, greenlet, frozenlist, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, pydantic, aiosignal, pydantic-settings, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/30\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 dataclasses-json-0.6.7 frozenlist-1.6.0 greenlet-3.2.2 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.25 langchain-community-0.3.24 langchain-core-0.3.60 langchain-text-splitters-0.3.8 langsmith-0.3.42 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 orjson-3.10.18 propcache-0.3.1 pydantic-2.11.4 pydantic-core-2.33.2 pydantic-settings-2.9.1 python-dotenv-1.1.0 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspect-0.9.0 typing-inspection-0.4.0 yarl-1.20.0 zstandard-0.23.0\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /home/codespace/.local/lib/python3.12/site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp312-cp312-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "Collecting groq\n",
      "  Downloading groq-0.25.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Downloading groq-0.25.0-py3-none-any.whl (129 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [groq]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 groq-0.25.0\n",
      "Collecting openai\n",
      "  Downloading openai-1.79.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Downloading openai-1.79.0-py3-none-any.whl (683 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.3/683.3 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [openai]2m2/3\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jiter-0.10.0 openai-1.79.0 tqdm-4.67.1\n",
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (4.67.1)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (2.6.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed huggingface-hub-0.31.4 regex-2024.11.6 safetensors-0.5.3 sentence-transformers-4.1.0 tokenizers-0.21.1 transformers-4.51.3\n",
      "Requirement already satisfied: huggingface_hub[hf_xet] in /home/codespace/.python/current/lib/python3.12/site-packages (0.31.4)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub[hf_xet]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub[hf_xet]) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub[hf_xet]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub[hf_xet]) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.1 (from huggingface_hub[hf_xet])\n",
      "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface_hub[hf_xet]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface_hub[hf_xet]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface_hub[hf_xet]) (2025.1.31)\n",
      "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: hf-xet\n",
      "Successfully installed hf-xet-1.1.2\n",
      "Requirement already satisfied: faiss-cpu in /home/codespace/.python/current/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /home/codespace/.local/lib/python3.12/site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.169.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pydantic in /home/codespace/.python/current/lib/python3.12/site-packages (from google-generativeai) (2.11.4)\n",
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/codespace/.local/lib/python3.12/site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.0rc1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/codespace/.local/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.25.0rc1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading google_api_python_client-2.169.0-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: uritemplate, pyasn1, protobuf, httplib2, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [google-generativeai]ogle-ai-generativelanguage]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cachetools-5.5.2 google-ai-generativelanguage-0.6.15 google-api-core-2.25.0rc1 google-api-python-client-2.169.0 google-auth-2.40.1 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!pip install PyPDF2\n",
    "!pip install langchain-community\n",
    "!pip install faiss-cpu\n",
    "!pip install groq\n",
    "!pip install openai\n",
    "!pip install tqdm\n",
    "!pip install sentence-transformers\n",
    "!pip install huggingface_hub[hf_xet]\n",
    "!pip install faiss-cpu\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a875319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import tqdm\n",
    "import glob\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "import google.generativeai as genai\n",
    "from groq import Groq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4b53272",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c27b72",
   "metadata": {},
   "source": [
    "## <b>Tasks (This part will be evaluated!)</b>\n",
    "### Notes on the following tasks:\n",
    "\n",
    "In this part of the exam, you will build a Retrieval-Augmented Generation (RAG) pipeline that efficiently retrieves medical information from the package inserts of common medications. Imagine you are developing a system for pharmacists or medical professionals to quickly and accurately answer questions about medications. The following five package inserts are provided as your data source:\n",
    "\n",
    "- [data/Amoxicillin.pdf](data/Amoxicillin.pdf)\n",
    "- [data/bisoprolol.pdf](data/bisoprolol.pdf)\n",
    "- [data/citalopram.pdf](data/citalopram.pdf)\n",
    "- [data/metformin.pdf](data/metformin.pdf)\n",
    "- [data/paracetamol.pdf](data/paracetamol.pdf)\n",
    "\n",
    "Your task is to implement a RAG pipeline that retrieves relevant information from these package inserts and integrates it into the answer generation process. Use the provided instructions and your knowledge from the exercises.\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "1. Read in the provided package inserts and extract all text.\n",
    "2. Split the extracted text into manageable chunks using a text splitter (e.g., `RecursiveCharacterTextSplitter`).\n",
    "3. Create embeddings for the text chunks using a suitable model.\n",
    "4. Index the embeddings in a vector store (e.g., FAISS).\n",
    "5. Develop an appropriate prompt template.\n",
    "6. Build the RAG chain.\n",
    "7. Automatically generate a list of 10 test questions using a language model.\n",
    "8. Let your RAG pipeline answer the 10 generated questions.\n",
    "\n",
    "### Submission documents:\n",
    "\n",
    "Your submission should include:\n",
    "- The completed notebook (this file).\n",
    "- the vector store\n",
    "\n",
    "<b style=\"color:blue;\">Notes on the following tasks:</b>\n",
    "<ul style=\"color:blue;\">\n",
    "  <li>Pay attention to the specific details provided for each task.</li>\n",
    "  <li>Solve each task using Python code. Integrate your code into the code cells for each task.</li>\n",
    "  <li>Present your solution(s) as requested in each task.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033f466",
   "metadata": {},
   "source": [
    "#### <b>Task (1): Read all 5 PDFs from the 'data' folder and store their content for further use</b>\n",
    "<b>Task details:</b>\n",
    "- The files are located in the 'data' folder..\n",
    "- Display the length of the resulting string (number of characters).\n",
    "- Show the first 100 characters in the notebook output.\n",
    "<b style=\"color: gray;\">(max. points: 2)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfcb555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "glob_path = \"data/*.pdf\"\n",
    "text = \"\"\n",
    "for pdf_path in tqdm.tqdm(glob.glob(glob_path)):\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PdfReader(file)\n",
    "         # Extract text from all pages in the PDF\n",
    "        text += \" \".join(page.extract_text() for page in reader.pages if page.extract_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07233c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Inhaltsverzeichnis\\nZusammensetzung\\nDarreichungsform und Wirkstoffmenge pro Einheit\\nIndikationen/Anwe'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the number of characters in the text\n",
    "print(len(text))\n",
    "\n",
    "# Show the first 100 characters of the text\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d4887",
   "metadata": {},
   "source": [
    "#### <b>Task (2): Split the text into chunks appropriate for the task. Specify an overlap as well. Give a reason for your choice</b>\n",
    "<b>Task details:</b>\n",
    "- Use the data from the previous task.\n",
    "- Show the total number of chunks in the notebook.\n",
    "- Show the length of the first chunk in the notebook.\n",
    "- Explain you reasoning\n",
    "<b style=\"color: gray;\">(max. points: 4)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21844664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93aad8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a splitter: 2000 characters per chunk with an overlap of 200 characters\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "# Split the extracted text into manageable chunks\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e4a316e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 98\n",
      "Preview of the first chunk: Inhaltsverzeichnis\n",
      "Zusammensetzung\n",
      "Darreichungsform und Wirkstoffmenge pro Einheit\n",
      "Indikationen/Anwendungsmöglichkeiten\n",
      "Dosierung/Anwendung\n",
      "Kontraindikationen\n",
      "Warnhinweise und Vorsichtsmassnahmen\n",
      "Inte\n"
     ]
    }
   ],
   "source": [
    "# Show the total number of chunks\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(\"Preview of the first chunk:\", chunks[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23affd5",
   "metadata": {},
   "source": [
    "##### Explanation (double click and add text): with almost 100 chunks i have enough to fill a vector with content. So when i retrive it, i can get a good quality of outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3fec8",
   "metadata": {},
   "source": [
    "#### <b>Task (3): Initialize an embedding model</b>\n",
    "<b>Task details:</b>\n",
    "- Choose a suitable embedding model from Huggingface.\n",
    "- [Huggingface models](https://huggingface.co/spaces/mteb/leaderboard).\n",
    "- Consider the size of the model. It should be runnable in your Codespace.\n",
    "- Choose a model appropriate for the data.\n",
    "\n",
    "<b style=\"color: gray;\">(max. points: 2)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "897716e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings  # For generating embeddings for text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed99968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "chunk_embeddings = model.encode(chunks, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80dc61",
   "metadata": {},
   "source": [
    "#### <b>Task (4): Create a vector store</b>\n",
    "<b>Task details:</b>\n",
    "- Create a vector store\n",
    "- store the vector store (this is also helpful in case the codespace or colab needs a restart)\n",
    "<b style=\"color: gray;\">(max. achievable points: 6)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c46e66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "d = chunk_embeddings.shape[1]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "077a187d-05be-4c30-a367-a4e1a19d4466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings in FAISS index: 98\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(chunk_embeddings)\n",
    "print(\"Number of embeddings in FAISS index:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d178ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"faiss/faiss_index.index\")\n",
    "with open(\"faiss/chunks_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17c8aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"faiss/faiss_index.index\")\n",
    "with open(\"faiss/chunks_mapping.pkl\", \"rb\") as f:\n",
    "    chunks = pickle.load(f)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa1d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e369261",
   "metadata": {},
   "source": [
    "#### <b>Task (5): Create a retriever function.</b>\n",
    "<b>Task details:</b>\n",
    "- Create a retriever function\n",
    "- Define the number of documents the retriever should return.\n",
    "- Test the retriever with the following query: `\"Welche Dosierung von Amoxicillin Axapharm wird für die Behandlung einer Endokarditis-Prophylaxe bei Erwachsenen empfohlen?\"`\n",
    "- If the retrieved chunks are not relevant, increase the number of chunks to be retrieved and repeat the query. \n",
    "- It does not have to be perfect; if nothing improves, continue with the current result.\n",
    "<b style=\"color: gray;\">(max. achievable points: 6)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "034ae6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def retrieve_texts(query, k, index, chunks, model):\n",
    "def retrieve_texts(query, k, index, chunks, model):\n",
    "    \"\"\"\n",
    "    Retrieve the top k similar text chunks and their embeddings for a given query.\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    retrieved_texts = [chunks[i] for i in indices[0]]\n",
    "    return retrieved_texts, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8465da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Welche Dosierung +von Amoxicillin Axapharm wird für die Behandlung einer Endokarditis-Prophylaxe bei Erwachsenen empfohlen?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef402de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Die Ther apie sollte über 48 bis 72 Stunden nach Erreichen einer klinischen Wirkung fortgesetzt werden. Bei einer Infektion, die durch β-\\nhämolysierende Streptok okken verursacht worden ist, empfiehlt es sich, während mindestens 10 T agen mit der Behandlung fortzufahren, um\\ndas A uftreten v on akutem rheumatischem Fieber oder einer Glomerulonephritis zu v erhindern.\\nFür die Behandlung v on erw achsenen P atienten und Kindern über 40 kg sollten Amo xicillin- Tabletten v erwendet werden.\\nÜbliche Dosierung\\nErwachsene und Kinder über 40 kg\\nLeichte bis mittelschwere Infektionen\\nAllgemeine Richtlinien: 1500-3000 mg Amo xicillin/T ag in 3-4 Einz eldosen.\\nMaximale Tagesdosis:  4000-6000 mg aufgeteilt in 3-4 Dosen.\\nDosierungsempfehlung:  3-4× täglich 375-750 mg.\\nZur Behandlung der Gonorrhoe (spezifische Urethritis) und der unk omplizierten Infektionen der unteren Harn wege (z.B . Zystitis, bakterielle\\nUrethritis) sowie zur Endokarditisproph ylaxe kann eine Einz eldosis v on 3 g Amo xicillin p .o. verabreicht werden.\\nKinder bis und mit 40 kg\\nAllgemeine Richtlinien:  50-100 mg/kg/T ag, aufgeteilt auf 3-4 Dosen.\\nMaximale Tagesdosis:  2000 mg, aufgeteilt auf 3-4 Dosen.\\nMaximale Einzeldosis:  50 mg/kg.\\nDosierungsempfehlung\\nNeu- und Frühgeborene sollen in der R egel parenter al behandelt werden wegen unsicherer R esorption (aktiv er Transport). P erorale\\nBehandlung frühestens ab 8 T agen.\\nGewicht ca. Alter Tagesdosis bei 50-100 mg/kg KG Dosierungsmöglichkeit/Tag\\n≤5 kg ≤3 Monate 250-500 mg 3-4× 100 mg\\n6-7 kg 3-6 Monate 350-700 mg 4× 100 mg oder\\n3× 200 mg\\n8-10 kg 6-12 Monate 500-1000 mg 3-4× 200 mg\\n11-15 kg 1-3 Jahre 750-1500 mg 4× 200 mg oder\\n3× 400 mg\\n16-20 kg 3-6 Jahre 1000-2000 mg 3-4× 400 mg\\n21-25 kg 6-8 Jahre 1250-2000 mg 3-4× 400 mg\\n26-30 kg 8-10 Jahre 1500-2000 mg 4× 400 mg\\n31-40 kg 10-12 Jahre 2000 mg 4× 400 mg\\nSchwere Infektionen\\nHier ist eine intr avenöse V erabreichungsart zu erwägen.\\nEndokarditis-Prophylaxe', 'gener alisierte exanthematöse Pustulosis (AGEP) wurden bei P atienten unter Behandlung mit Beta-Laktam- Antibiotika, einschliesslich\\nAmoxicillin, berichtet (siehe auch «Unerwünschte Wirkungen»). Beim A uftreten solcher R eaktionen ist Amo xicillin Axapharm 200 mg/4 ml\\nunverzüglich abzusetz en und eine Alternativther apie ist in Erwägung zu ziehen.\\nAmoxicillin sollte mit V orsicht angewendet werden bei P atienten mit einer v orangegangenen Historie einer Arzneimittelwirkung mit\\nEosinophilie und systemischen S ymptomen (DRES S-Syndrom) in Zusammenhang mit anderen Arzneimitteln, da v on einem erneuten, durch\\nAmoxicillin induzierten A ufflammen v on DRES S berichtet wurde.\\nBei längerer An wendung kann es zum Überwuchern resistenter K eime und/oder Pilz e kommen. Beim A uftreten einer solchen Superinfektion\\nmuss sofort eine entsprechende Ther apie eingeleitet werden.\\nDas A uftreten v on Diarrhö während oder nach der Behandlung mit Amo xicillin Axapharm 200 mg/4 ml, besonders, wenn diese sch wer,\\nanhaltend und/oder blutig v erläuft, kann ein S ymptom für eine Infektion mit Clostridium difficile sein. Die sch werste V erlaufsform ist die\\npseudomembr anöse K olitis. Sollte der V erdacht auf eine der artige K omplikation bestehen, so ist die Behandlung mit Amo xicillin Axapharm\\n200 mg/4 ml un verzüglich abzubrechen und der P atient sollte eingehend untersucht werden um allenfalls eine spezifische Antibiotikather apie\\n(z.B. Metronidaz ol, Vancom ycin) einzusetz en. Der Einsatz v on peristaltikhemmenden Mitteln ist in dieser klinischen Situation k ontraindiziert.\\nBei Patienten unter Amo xicillin und or alen Antik oagulantien wurde selten über eine abnorme V erlängerung der Prothrombinz eit (erhöhte INR)\\nberichtet. W erden gleichz eitig Antik oagulantien v erordnet, sollte deshalb eine angemessene Überw achung v orgenommen werden. Um den\\ngewünschten Gr ad der Antik oagulation aufrechtzuerhalten, muss die Dosis der or alen Antik oagulantien möglicherweise angepasst werden.', 'Distribution\\nAmoxicillin wird zu ca. 18% an Plasmaproteine gebunden. Das V erteilungsv olumen v on Amo xicillin beträgt 22 Liter .\\nDa nach or aler V erabreichung v on Amo xicillin Axapharm 200 mg/4 ml hohe Serum-K onzentrationen v on Amo xicillin erreicht werden, kann\\nman mit einer guten P enetration in die Körperflüssigk eiten rechnen.\\nAmoxicillin diffundiert gut ins Gewebe, gelangt aber nur in geringen Mengen in den Liquor cerebrospinalis v on Probanden, deren Meningen\\nnicht entzündet sind.\\nDie K onzentrationen v on Amo xicillin in der Muttermilch sind gering.\\nAmoxicillin diffundiert in die Placenta.\\nMetabolismus\\nEtwa 20-30% einer or al verabreichten Amo xicillin-Dosis werden in der Leber metabolisiert. Der Hauptmetabolit ist die bakteriologisch\\ninaktiv e Penicilloinsäure, die renal ausgeschieden wird.1 3 3\\n3 3 3\\n4 4 4 4\\n5 5 5 5\\n11 11\\n6 6 12, 3 12, 3\\n7 7\\n8\\n8\\n9 9\\n3 3\\n10\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n1212/12/2024, 18:30 compendium.ch\\nhttps://compendium.ch/product/1376868-amoxicillin-axapharm-plv-200-mg-4ml-f-susp/mpro 6/7 // Contact ModalElimination\\nDie Eliminationshalbwertsz eit von Amo xicillin beträgt bei normaler Nierenfunktion 60-90 Minuten.\\nIn den ersten sechs Stunden nach intr avenöser V erabreichung einer Standarddosis werden 60-70% der v erabreichten Dosis als\\nunveränderter Wirkstoff in hoher K onzentration im Urin ausgeschieden.\\n10-25% der Initialdosis werden als inaktiv e Penicilloinsäure ausgeschieden. Der Q -Wert beträgt 0.15. Durch gleichz eitige V erabreichung v on\\nProbenecid kann die tubuläre Sekretion v on Amo xicillin v erzögert werden: der Plasmaspiegel wird dadurch um ca. 60% erhöht und die renale\\nElimination um ca. 20% her abgesetzt.\\nNach V erabreichung v on 3 g p .o. erreichen die Harnspiegel Spitz enwerte bis zu 5500 µg/ml.\\nKinetik spezieller Patientengruppen\\nDie Elimination v on Amo xicillin kann bei Niereninsuffizienz je nach Sch weregr ad verzögert sein (vgl. «Spezielle Dosierungsan weisungen»).'], array([[7.5899625, 7.825759 , 7.973072 ]], dtype=float32))\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testen des retrievers\n",
    "retrieved_texts = retrieve_texts(query, 3, index, chunks, model)\n",
    "\n",
    "print(retrieved_texts)\n",
    "print(len(retrieved_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd43ac",
   "metadata": {},
   "source": [
    "#### <b>Task (6): Implement a reusable RAG function and prompt template</b>\n",
    "<b>Task details:</b>\n",
    "- Write a function `get_answer_and_documents` that answers a question using your RAG pipeline.\n",
    "- The function should:\n",
    "  - Take as parameters: the question (`question`), the number of documents to retrieve (`k`), the FAISS index (`index`), and the list of text chunks (`chunks`).\n",
    "  - The prompt template should be tailored to the medical context, address medical professionals, and instruct the model to answer concisely and in German, using only the provided context. This is part of the task.\n",
    "  - Return both the answer and the retrieved documents.\n",
    "- Test the function with the question: `Ab welcher Kreatinin-Clearance ist die Einnahme von Metformin kontraindiziert?`\n",
    "\n",
    "<b style=\"color: gray;\">(max. achievable points: 8)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae8ae141",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3551908159.py, line 15)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# set language model and output parser\n",
    "def answer_query(query, k, index,texts):\n",
    "  \"\"\"\n",
    "    Retrieve the top k similar text chunks for the given query using the retriever,\n",
    "    inject them into a prompt, and send it to the Groq LLM to obtain an answer.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The user's query.\n",
    "    - k (int): Number of retrieved documents to use.\n",
    "    - groq_api_key (str): Your Groq API key.\n",
    "    \n",
    "    Returns:\n",
    "    - answer (str): The answer generated by the LLM.\n",
    "    \"\"\"\n",
    "    model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    chunk_embeddings = model.encode(chunks, convert_to_numpy=True)\n",
    "    retrieved_texts, _ = retrieve_texts(query, k, index, texts, model)\n",
    "    \n",
    "    # Combine the retrieved documents into a single context block.\n",
    "    context = \"\\n\\n\".join(retrieved_texts)\n",
    "    \n",
    "    # Build a prompt that instructs the LLM to answer the query based on the context.\n",
    "    prompt = (\n",
    "        \"Beantworte die folgende Frage mit dem angehängten Medizinischen Kontext\"\n",
    "        \"Erkläre es als wärst du ein Arzt der es einem anderen Arzt erklären.\\n\\n\"\n",
    "        \"Context:\\n\" + context + \"\\n\\n\"\n",
    "        \"Question: \" + query + \"\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    \n",
    "    # Initialize the Groq client and send the prompt.\n",
    "    client = Groq(api_key=groq_api_key)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    llm = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"llama-3.3-70b-versatile\"\n",
    "    )\n",
    "    \n",
    "    # Extract and return the answer.\n",
    "    answer = llm.choices[0].message.content\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c380d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "query = \"Ab welcher Kreatinin-Clearance ist die Einnahme von Metformin kontraindiziert?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa1a3d91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# print result of test query with your chain (hint: input is a dictionary)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43manswer_query\u001b[49m(query, \u001b[32m4\u001b[39m, index, chunks))\n",
      "\u001b[31mNameError\u001b[39m: name 'answer_query' is not defined"
     ]
    }
   ],
   "source": [
    "# print result of test query with your chain (hint: input is a dictionary)\n",
    "print(answer_query(query, 4, index, chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34584dc",
   "metadata": {},
   "source": [
    "#### <b>Task (7): Implement a HyDE Query Transformation for RAG</b>\n",
    "<b>Task details:</b>\n",
    "- Implement a function that applies the HyDE strategy in your RAG pipeline.\n",
    "- add your HyDe transformation to your pipeline\n",
    "- Display the intermediate transformation (print statement within function is enough) and the final answer in the notebook.\n",
    "<b style=\"color: gray;\">(max. achievable points: 6)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "189b4fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.37-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata (438 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
      "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13,>=0.12.36 (from llama-index)\n",
      "  Downloading llama_index_core-0.12.37-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.3.42-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.79.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (3.11.18)\n",
      "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (2024.6.1)\n",
      "Requirement already satisfied: httpx in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (3.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (2.2.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /home/codespace/.python/current/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.36->llama-index) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (9.1.2)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (0.9.0)\n",
      "Collecting wrapt (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (1.20.0)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /home/codespace/.local/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (4.3.6)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.3)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.36->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.36->llama-index) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.36->llama-index) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.36->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.36->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.36->llama-index) (0.4.0)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.21-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.22-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.22 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from llama-cloud-services>=0.6.22->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
      "Collecting platformdirs (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index)\n",
      "  Downloading platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-cloud-services>=0.6.22->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.36->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.36->llama-index) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/codespace/.python/current/lib/python3.12/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.36->llama-index) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.36->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.36->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/codespace/.local/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.36->llama-index) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/codespace/.local/lib/python3.12/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
      "Downloading llama_index-0.12.37-py3-none-any.whl (7.1 kB)\n",
      "Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.37-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_llms_openai-0.3.42-py3-none-any.whl (23 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
      "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading llama_parse-0.6.22-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.22-py3-none-any.whl (37 kB)\n",
      "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
      "Downloading click-8.2.0-py3-none-any.whl (102 kB)\n",
      "Downloading platformdirs-4.3.8-py3-none-any.whl (18 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, pypdf, platformdirs, griffe, click, aiosqlite, tiktoken, nltk, deprecated, llama-cloud, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "\u001b[2K  Attempting uninstall: platformdirs━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/28\u001b[0m [pypdf]\n",
      "\u001b[2K    Found existing installation: platformdirs 4.3.6━━━━━━━━━━━\u001b[0m \u001b[32m 4/28\u001b[0m [pypdf]\n",
      "\u001b[2K    Uninstalling platformdirs-4.3.6:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/28\u001b[0m [pypdf]\n",
      "\u001b[2K      Successfully uninstalled platformdirs-4.3.6━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/28\u001b[0m [pypdf]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/28\u001b[0m [llama-index]\u001b[0m [llama-index-cli]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiosqlite-0.21.0 banks-2.1.2 click-8.2.0 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.7.3 llama-cloud-0.1.19 llama-cloud-services-0.6.22 llama-index-0.12.37 llama-index-agent-openai-0.4.7 llama-index-cli-0.4.1 llama-index-core-0.12.37 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.42 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.22 nltk-3.9.1 platformdirs-4.3.8 pypdf-5.5.0 striprtf-0.0.26 tiktoken-0.9.0 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88ecd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292669b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'IndexFlatL2' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m query_engine = \u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m response = query_engine.query(query)\n\u001b[32m      3\u001b[39m display(Markdown(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<b>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</b>\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: 'IndexFlatL2' object is not callable"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(query)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "hyde_query_engine = TransformQueryEngine(, hyde)\n",
    "response = hyde_query_engine.query(query)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query_hyde(query):\n",
    "    \n",
    "    return new_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16e7d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(query, groq_api_key):\n",
    "    \"\"\"\n",
    "    Rewrite the user's query into to potentially improve retrieval.\n",
    "    Parameters:\n",
    "    - query (str): The original user query.\n",
    "    - groq_api_key (str): Your Groq API key.\n",
    "    \n",
    "    Returns:\n",
    "    - rewritten_query (str): The rewritten query.\n",
    "    \"\"\"\n",
    "    client = Groq(api_key=groq_api_key)\n",
    "    # Build a prompt for rewriting the query\n",
    "    rewriting_prompt = (\n",
    "        \"Rewrite the following query into a format, such that it can be answered by looking at medical guidelines. \"\n",
    "        \"Keep the keywords but ensure that it is close to a format, such as in medical guidelines. Just answer with the rewritten query\\n\\n\"\n",
    "        \"Query: \" + query\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": rewriting_prompt}\n",
    "    ]\n",
    "    \n",
    "    # Use the same model (for example, llama) to perform query rewriting\n",
    "    llm = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "    )\n",
    "    rewritten_query = llm.choices[0].message.content.strip()\n",
    "    return rewritten_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bfb9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_rewriting(query, k, index, texts):\n",
    "\"\"\"\n",
    "    Retrieve the top k similar text chunks for the given query using a retrieval method\n",
    "    with query rewriting, inject them into a prompt, and send it to the Groq LLM (using llama)\n",
    "    to obtain an answer.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The user's query.\n",
    "    - k (int): Number of retrieved documents to use.\n",
    "    - index: The FAISS index.\n",
    "    - texts (list): The tokenized text chunks mapping.\n",
    "    - groq_api_key (str): Your Groq API key.\n",
    "    \n",
    "    Returns:\n",
    "    - answer (str): The answer generated by the LLM.\n",
    "    \"\"\"\n",
    "    model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    # Use the new retrieval function with query rewriting.\n",
    "    rewritten_query = rewrite_query(query, groq_api_key)    \n",
    "    print(\"Rewritten Query:\", rewritten_query) ## FYI\n",
    "\n",
    "    retrieved_texts, _ = retrieve_texts(rewritten_query, k, index, texts, model)\n",
    "    \n",
    "    # Combine the retrieved documents into a single context block.\n",
    "    context = \"\\n\\n\".join(retrieved_texts)\n",
    "    \n",
    "    # Build a prompt that instructs the LLM to answer the query based on the context.\n",
    "    prompt = (\n",
    "        \"Answer the following question using the provided context. \"\n",
    "        \"Explain it as if you are explaining it to a 5 year old.\\n\\n\"\n",
    "        \"Context:\\n\" + context + \"\\n\\n\"\n",
    "        \"Question: \" + query + \"\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    \n",
    "    # Initialize the Groq client and send the prompt.\n",
    "    client = Groq(api_key=groq_key)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    llm = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"llama-3.3-70b-versatile\"\n",
    "    )\n",
    "    \n",
    "    # Extract and return the answer.\n",
    "    answer = llm.choices[0].message.content\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Was ist der wichtigste Faktor bei der Diagnostizierung von Asthma?\"\n",
    "answer = answer_query_with_rewriting(query, 3, index, model)\n",
    "print(\"LLM Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd20f4",
   "metadata": {},
   "source": [
    "#### <b>Task (7): Generate a list of test questions</b>\n",
    "<b>Task details:</b>\n",
    "- Create a Python list with 10 questions about the provided medications.\n",
    "- The questions should be automatically generated using a language model.\n",
    "- You may use chunks from the package inserts as inspiration, but this is not required.\n",
    "- At the end, print out your list of questions.\n",
    "\n",
    "<b style=\"color: gray;\">(max. achievable points: 6)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ca399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Here are 10 questions about the provided medications:\n",
      "\n",
      "1. **What is the primary indication for Amoxicillin, and what type of infections is it commonly used to treat?**\n",
      "\n",
      "2. **What is the mechanism of action of Bisoprolol, and how does it differ from other beta-blockers in terms of its selective beta-1 receptor blockade?**\n",
      "\n",
      "3. **What are the common side effects of Citalopram, and how does it compare to other selective serotonin reuptake inhibitors (SSRIs) in terms of its tolerability and efficacy?**\n",
      "\n",
      "4. **What is the primary use of Metformin, and how does it help to regulate blood glucose levels in patients with type 2 diabetes?**\n",
      "\n",
      "5. **What is the recommended dosage of Paracetamol for adults, and what are the potential risks of overdosing on this medication?**\n",
      "\n",
      "6. **Can Amoxicillin be used to treat viral infections, and what are the implications of prescribing antibiotics for non-bacterial infections?**\n",
      "\n",
      "7. **How does Bisoprolol affect heart rate and blood pressure, and what are the potential benefits and drawbacks of using this medication in patients with cardiovascular disease?**\n",
      "\n",
      "8. **What is the potential for Citalopram to interact with other medications, and how can healthcare providers minimize the risk of adverse interactions?**\n",
      "\n",
      "9. **What are the potential gastrointestinal side effects of Metformin, and how can patients minimize the risk of these side effects when taking this medication?**\n",
      "\n",
      "10. **Can Paracetamol be used in combination with other medications, such as opioids or NSAIDs, and what are the potential risks and benefits of using these combination therapies?**\n",
      "\n",
      "Let me know if you want me to provide answers to these questions.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=groq_key)\n",
    "\n",
    "llm = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You re a medical profesional \\\n",
    "            generate 10 question about the provided medications\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"generate 10 question about medications (Amoxicillin,bisoprolol, citalopram, metformin, paracetamol )\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    \n",
    ")\n",
    "\n",
    "print(llm.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fbd4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"\"]\n",
    "questions.append(llm.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e76e6700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage 1: \n",
      "Frage 1: Here are 10 questions about the provided medications:\n",
      "\n",
      "1. **What is the primary indication for Amoxicillin, and what type of infections is it commonly used to treat?**\n",
      "\n",
      "2. **What is the mechanism of action of Bisoprolol, and how does it differ from other beta-blockers in terms of its selective beta-1 receptor blockade?**\n",
      "\n",
      "3. **What are the common side effects of Citalopram, and how does it compare to other selective serotonin reuptake inhibitors (SSRIs) in terms of its tolerability and efficacy?**\n",
      "\n",
      "4. **What is the primary use of Metformin, and how does it help to regulate blood glucose levels in patients with type 2 diabetes?**\n",
      "\n",
      "5. **What is the recommended dosage of Paracetamol for adults, and what are the potential risks of overdosing on this medication?**\n",
      "\n",
      "6. **Can Amoxicillin be used to treat viral infections, and what are the implications of prescribing antibiotics for non-bacterial infections?**\n",
      "\n",
      "7. **How does Bisoprolol affect heart rate and blood pressure, and what are the potential benefits and drawbacks of using this medication in patients with cardiovascular disease?**\n",
      "\n",
      "8. **What is the potential for Citalopram to interact with other medications, and how can healthcare providers minimize the risk of adverse interactions?**\n",
      "\n",
      "9. **What are the potential gastrointestinal side effects of Metformin, and how can patients minimize the risk of these side effects when taking this medication?**\n",
      "\n",
      "10. **Can Paracetamol be used in combination with other medications, such as opioids or NSAIDs, and what are the potential risks and benefits of using these combination therapies?**\n",
      "\n",
      "Let me know if you want me to provide answers to these questions.\n"
     ]
    }
   ],
   "source": [
    "for i, question in enumerate(questions):\n",
    "    i +=1\n",
    "    print(\"Frage \" + str(1) + \": \" + question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e3225",
   "metadata": {},
   "source": [
    "#### <b>Task (8): Let your retriever answer the 10 generated questions.</b>\n",
    "<b>Task details:</b>\n",
    "- Use the 10 generated questions and have them answered by your RAG chain.\n",
    "- For each question, output both the retrieved documents and the answer.\n",
    "- Provide your own assessment of whether your chain works well or not.\n",
    "- Give an example of what worked well and what did not.\n",
    "\n",
    "<b style=\"color: gray;\">(max. achievable points: 6)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909478da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beantwortung der 10 generierten Fragen\n",
    "\n",
    "for question in questions: \n",
    "    \n",
    "    lient = Groq(api_key=groq_key)\n",
    "\n",
    "llm = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You re a medical profesional \\\n",
    "            \"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"answer these questions\"),\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    \n",
    ")\n",
    "\n",
    "print(llm.choices[0].message.content)\n",
    "    \n",
    "    answer =  answer_query_with_rewriting(question, 4, index, chunks)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8e4d8",
   "metadata": {},
   "source": [
    "#### <b> TASK (9) Your assessment of the quality (double-click to edit the cell below):</b>\n",
    "\n",
    "- Briefly describe what seems to work well in your RAG pipeline based on the answers to the 10 generated questions above.\n",
    "- Give at least one example of a question/answer pair that worked particularly well.\n",
    "- Point out at least one aspect or example where the pipeline could be improved or did not work as expected.\n",
    "\n",
    "<b style=\"color: gray;\">(max. achievable points: 2)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc97c26",
   "metadata": {},
   "source": [
    "Because i didnt manage to create a functional RAG pipeline i cannot asses this question. SO i imagine i can get a Folgefehler in this Part."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff525b1e",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6cae5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "POSIX\n",
      "Linux | 6.8.0-1027-azure\n",
      "Datetime: 2025-05-20 09:24:19\n",
      "Python Version: 3.12.1\n",
      "IP Address: 127.0.0.1\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('IP Address:', socket.gethostbyname(socket.gethostname()))\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
